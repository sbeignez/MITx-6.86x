{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27. Lecture 15. Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.1. Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Understand what Generative Models are and how they work\n",
    "* Understand estimation and prediction phases of generative models\n",
    "* Derive a relation connecting generative and discriminative models\n",
    "* Derive **Maximum Likelihood Estimates (MLE)** for multinomial and Gaussian generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.2. Generative vs Discriminative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Discriminative models | Generative models\n",
    "--- | ---\n",
    "learn the **decision boundary** between the classes | model the **probability distribution** of each class\n",
    "need labeled data, more data | unlabeled data\n",
    "Ex: Classification > Find a Separator (decision boundary) | Find a structure in the group of data, with a probalistic view\n",
    ". | KNN is exmaple of structured data\n",
    "\n",
    "![Discriminative vs Generative](img/27.L15.1.png)\n",
    "\n",
    "2 types of generative models:\n",
    "1. Multinomials Models\n",
    "2. Gaussians Models\n",
    "\n",
    "2 questions about the models:\n",
    "- **Estimation**: How to estimate the model?\n",
    "- **Prediction**: ..\n",
    "\n",
    "Fit probability distribution to the group of + and - classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.3. Simple Multinomial Generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex: documents of text  \n",
    "Model will generate a document, by picking a word at a time\n",
    "vs. vector of fixed lenght\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's:\n",
    "* M: a multinomial model (to generate text in documents)\n",
    "* W: a vocabulary\n",
    "* $ p(w|\\theta) $ with $\\theta$ the parameter of the model, or $ \\theta_w$: capture the likelihood of selecting a word, given all possibilities.\n",
    "\n",
    "To have a valid probability distribution, the constraints are:\n",
    "* $ \\theta_w \\ge 0 $  \n",
    "  (each probability is greater than 0, can't be negative)\n",
    "* $ \\sum_{w \\in W} \\theta_w = 1 $  \n",
    "  (the sum of all probabilities is equal to 1)\n",
    "\n",
    "\n",
    "Notes:\n",
    "* Why is this model called \"multinomial\" generative model?\n",
    "  * because of the number of outcomes. If there are two outcomes it is binomial. In the context of the example, there are many words (more than two), so it's called multinomial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.4. Likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to calculate the probability $p$ to generate a document $D$:  \n",
    "1. it's the product of the probabilities to pick each n words of D\n",
    "$$ p(D | \\theta) = \\prod_{i=1}^n \\theta_{w_i} $$  \n",
    "2. or the product of the probability of each word to the power of its occurence\n",
    "$$ p(D | \\theta) = \\prod_{w \\in W} \\theta_{w}^{count(w)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO what happen if prob = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Let's:\n",
    "* The vocabulary $W = \\{ \"cat\", \"dog\" \\}$\n",
    "* The model $M_1$ with paramter $\\theta_1: \\theta_{cat}=0.3, \\theta_{dog}=0.7 $\n",
    "* The model $M_2$ with paramter $\\theta_2: \\theta_{cat}=0.9, \\theta_{dog}=0.1 $\n",
    "\n",
    "A document $D = { cat, cat, dog}$ \n",
    "\n",
    "Compute the probabilities, that each models, generates the document:\n",
    "* $ p(D | \\theta_1) = .3^2 + .7 = 0.79 $\n",
    "* $ p(D | \\theta_2) = .9^2 + .1 = 0.91 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "* In the example before, each word is generated independently of all other words.\n",
    "* In the case of common languages (like English), this assumption is not realistic, as words  probability of appearance depends of surrounding words, rules of grammar, sentence structure.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Maximum Likelihood Estimate\n",
    "\n",
    "How to use the training data to find the best parameter that fit data?\n",
    "\n",
    "Find $\\theta$ such as:\n",
    "$$max_{\\theta} \\ p(D|\\theta)$$ \n",
    "$$max_{\\theta} \\prod_{w \\in W} \\theta_w^{count(w)}$$ \n",
    "\n",
    "It's equivalent to (and easier than) maximise the log of the product (which become a sum):\n",
    "\n",
    "$$max_{\\theta} \\sum_{w \\in W} log(\\theta_w^{count(w)}) $$\n",
    "$$max_{\\theta} \\sum_{w \\in W} count(w) * log(\\theta_w) $$\n",
    "\n",
    "\n",
    "Note:\n",
    "* Log, usually refers to the logarithm of base 10, or common logarithm\n",
    "* Ln, the natural logarithm, is the log base e. $ln x = log_e x$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case n=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve first for a trivial case, the vocabulary W has only 2 words (symbols).\n",
    "\n",
    "$ W = \\{0,1\\} $, (n = 2)\n",
    "\n",
    "Then:\n",
    "* $\\theta_0 = \\theta $ and $ \\theta_1 = 1 - \\theta $\n",
    "\n",
    "$max_{\\theta}$ of $[count(w=0) * log(\\theta_0) + count(w=1) * log(\\theta_1)]$  \n",
    "$max_{\\theta}$ of: $count(0) * log(\\theta) + count(1) * log(1 - \\theta)$\n",
    "\n",
    "To find the max, we search the 0 of the derivative:\n",
    "\n",
    "$$ d / d \\theta  count(0) * log(\\theta) + count(1) * log(1 - \\theta) = 0 $$\n",
    "\n",
    "$$ { count(0) \\over \\theta} + (-1) *{count(1) \\over (1-\\theta)} = 0 $$\n",
    "\n",
    "$$ (1-\\theta) * count(0) - \\theta * count(1) = 0 $$\n",
    "\n",
    "$$ \\theta = { count(0) \\over (count(0) + count(1)) } $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:  \n",
    "The minimal number of parameters that a model need to be defined is count(w) - 1\n",
    "* For count(w) = 2, only $\\theta_1$ is needed, because $\\theta_2 = 1 -\\theta_1$\n",
    "* For count(w) = 3, only $\\theta_1$ and $\\theta_2$ is needed, because $\\theta_3 = 1 -\\theta_1 -\\theta_2$\n",
    "* etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maximum Likelihood Estimate (MLE) is a very general method that can be applied to both continuous and discrete distributions, such as poisson distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.6. MLE for Multinomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case: n > 2\n",
    "\n",
    "Vocabulary on any length\n",
    "\n",
    "$$ \\theta_w = { count(w) \\over \\sum_{w \\in W} (count(n)) } $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technic is also applicable to a collection of documents $D_1, ..., D_n$, By concatenating all the documents $D_i$.  \n",
    "\n",
    "assumption is that the words are generated independently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.7. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ log ({p(+) \\over p(-)}) $$\n",
    "\n",
    "$$ ...$$\n",
    "\n",
    "Linear classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.8. Prior, Posterior and Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  27.9. Gaussian Generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.10. MLE for Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
